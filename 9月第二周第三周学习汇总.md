# 2022年9月第二周第三周学习汇总——宋世淼

[学习笔记.md](学习笔记.md)



## 一、线性回归

- 1.1 原理
- 1.2 所做实验代码



### 1.1 原理

**直接求解**：
$$
J(\theta) = \frac{1}{2}\sum_{i=1}^{m}(h_\theta(x^{(i)})-y^{(i)})^2 = \frac{1}{2}(X\theta-y)^T(X\theta-y)
$$
另偏导等于0：
$$
\theta = (X^TX)^{-1}X^Ty
$$
**机器学习优化的思想**：

- 批量梯度下降：容易得到最优解，但是由于每次考虑所有样本，速度慢。
  $$
  \frac{\partial J(\theta)}{\partial \theta_j} = -\frac{1}{m}\sum_{i=1}^{m}(y^i-h_\theta(x^i))x_j^i\theta_j^\prime = \theta_j+\frac{1}{m}\sum_{i=1}^{m}(y^i-h_\theta(x^i))x_j^i
  $$

- 随机梯度下降(SGD)：每次找一个样本，迭代速度快，但不一定每次都朝着收敛方向。
  $$
  \theta_j^\prime = \theta_j + (y^i-h_\theta(x^i))x_j^i
  $$

- 小批量梯度下降(MiniBatch)：每次更新选择一小部分数据来算。
  $$
  \theta_j := \theta_j - \alpha\frac{1}{10}\sum_{k=i}^{i+9}(h_\theta(x^{(k)})-y^{(k)})x_j^{(k)}
  $$



### 1.2 实验代码

- [单变量线性回归实验 UnivariateLinearRegression.ipynb](LinearRegression/UnivariateLinearRegression.ipynb)

  ![result](LinearRegression/img/single_result.png)

  

- [多特征线性回归实验 MultivariateLinearRegression.ipynb](LinearRegression/MultivariateLinearRegression.ipynb)

![multi_result](LinearRegression/img/multi_result.png)



- [非线性回归实验 Non_linearRegression.ipynb](LinearRegression/Non_linearRegression.ipynb)

![nonlinear_result](LinearRegression/img/nonlinear_result.png)



- [线性回归实验 LinearRegressionExperiment.ipynb](LinearRegression/LinearRegressionExperiment.ipynb)

  该实验做了对比实验，主要有：

  - **不同学习率(learning rate)对训练结果的影响**：

    ![lr](LinearRegression/img/lr.png)

    可以看出，$lr$ 越小，拟合效果越好（训练时间会越长）。

  - **不同梯度下降策略的对比实验**：

    ![compare](LinearRegression/img/compare.png)

    可以看出批量梯度下降效果最好（容易得到最优解，但用时长）；SGD不是每次都朝着收敛的方向下降（抖动最严重）；小批量梯度下降可以看出明显的折线（每次更新选择一小部分数据）。

  - **多项式回归实验**：

    将原始数据转换成更高维的数据进行训练，对比不同多项式最大特征次数的拟合情况

    ![degree](LinearRegression/img/degree.png)

    可以看出，多项式次数越高，拟合力度越大，模型会越容易过拟合。

  - **正则化实验**：

    对训练数据加上一个惩罚项，来预防模型过拟合。惩罚因子一般有 ：

    - $L_1$ 范数：$\sum_i|\theta_i|$ 
    - $L_2$ 范数：$(\sum_i\theta_i^2)^\frac{1}{2}$ 

    还有一个重要的参数 $\alpha$ 来表示惩罚的力度。

    ![L1](LinearRegression/img/L1.png)

    ![L2](LinearRegression/img/L2.png)

    上图分别为用 $L_1$ 与 $L_2$ 惩罚因子所做的图，可以看出 $\alpha$ 越大，曲线越平滑，对过拟合的抑制能力就越强。



## 二、模型评估方法

[model_evaluation_methods.ipynb](ModelEvaluationMethods/model_evaluation_methods.ipynb)



### 2.1 交叉验证思想

![cross_val](ModelEvaluationMethods/img/cross_validation.png)

将数据集切分为训练集和测试集，又将训练集切分，一部分用于训练，一部分用于验证。交叉验证的目的是训练过程中验证模型的性能，以便减少诸如过拟合和选择偏差等问题。



### 2.2 Confusion Matrix 混淆矩阵

|         二分类问题          |      相关（Relevant），正类       |     无关（NonRelevant），负类     |
| :-------------------------: | :-------------------------------: | :-------------------------------: |
|    被检索到（Retrieved）    |  true positive(TP 正类判定为正)   | false positive(FP 负类判定为正类) |
| 未被检索到（Not Retrieved） | false negative(FN 正类判定为负类) | true negative(TN 负类判定为负类)  |

由混淆矩阵引申出的概念有：

- **accuracy**
  $$
  accuracy=\frac{TP+TN}{TP+TN+FP+FN}=\frac{TP+TN}{all\ data}
  $$
  

- **Precision  Recall**
  $$
  precision=\frac{TP}{TP+FP}
  $$
   
  $$
  recall=\frac{TP}{TP+FN}
  $$
  

- **$F_1$ score**
  $$
  F_1=\frac{2}{\frac{1}{precision}+\frac{1}{recall}}=\frac{2\cdot precision\cdot recall}{precision+recall}
  $$
  precision 和 recall 的调和平均值。

- **ROC curves & AUC**

  ROC曲线的纵坐标 TPR 在数值上等于 positive class 的 recall；横坐标 FPR 在数值上等于 （1- negative class 的 recall）：
  $$
  TPR=\frac{TP}{TP+FN}=recall_{positive}
  $$

  $$
  FPR = \frac{FP}{FP+TN}=\frac{FP+TN-TN}{FP+TN}\\=1-\frac{TN}{FP+TN}=1-recall_{negative}
  $$

  ROC曲线越趋近左上角表明模型性能越好。

  AUC值是ROC曲线下的面积，AUC值越接近于1，表明模型性能越好。